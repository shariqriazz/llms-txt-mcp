# --- Tavily API Configuration ---
# Required for topic discovery in ragdocs_generate_llms_full
TAVILY_API_KEY=YOUR_TAVILY_API_KEY_HERE

# --- LLM Processing Configuration (for ragdocs_generate_llms_full) ---
# Specifies the provider for LLM processing. Choose 'gemini' (default) or 'ollama'.
LLM_PROVIDER=gemini
# The specific model name for the chosen LLM_PROVIDER.
# Defaults to 'gemini-2.0-flash' if provider is 'gemini', or 'llama3.1:8b' if provider is 'ollama'.
# Example: gemini-2.0-flash, llama3.1-4m, llama3.1:8b
LLM_MODEL=gemini-2.0-flash
# Required if LLM_PROVIDER is 'gemini'. Get from Google AI Studio.
GEMINI_API_KEY=YOUR_GOOGLE_AI_STUDIO_KEY_HERE
# Optional: Base URL for your Ollama instance if LLM_PROVIDER is 'ollama' and it's not at the default location.
# Example: http://localhost:11434 or http://host.docker.internal:11434
# OLLAMA_BASE_URL=

# --- RAGDocs Qdrant Configuration ---
# URL of your Qdrant instance. Required for all RAGDocs tools.
QDRANT_URL=http://localhost:6333
# Optional: API key for Qdrant Cloud or secured instances.
# QDRANT_API_KEY=YOUR_QDRANT_API_KEY_HERE

# --- RAGDocs Embedding Configuration ---
# Specifies the embedding model provider. Choose one: 'openai', 'ollama', 'google'. Required for RAGDocs indexing/search.
EMBEDDING_PROVIDER=ollama

# --- OpenAI Embedding Settings (if EMBEDDING_PROVIDER=openai) ---
# Required if EMBEDDING_PROVIDER is 'openai'.
# OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE
# Optional: Base URL for OpenAI-compatible APIs (e.g., Together.ai, Anyscale).
# OPENAI_BASE_URL=

# --- Ollama Embedding Settings (if EMBEDDING_PROVIDER=ollama) ---
# Required if EMBEDDING_PROVIDER is 'ollama'. The model name to use for embeddings.
# Example: nomic-embed-text, mxbai-embed-large
OLLAMA_MODEL=nomic-embed-text
# Note: Ollama connection URL is typically handled by the OLLAMA_HOST env var used by the 'ollama' library, or defaults to http://localhost:11434.
# You might set OLLAMA_HOST separately if needed globally for the ollama library.

# --- Google (Gemini) Embedding Settings (if EMBEDDING_PROVIDER=google) ---
# Required if EMBEDDING_PROVIDER is 'google'. Uses the same GEMINI_API_KEY as LLM processing.
# Optional: Specific Gemini embedding model name (defaults to models/embedding-001).
# EMBEDDING_MODEL=models/embedding-001
# Optional: A fallback Gemini embedding model name if the primary fails.
# GEMINI_FALLBACK_MODEL=text-embedding-004